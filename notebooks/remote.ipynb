{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote Agents\n",
    "\n",
    "When agentic AI application grows, and so does the number of agents required, it is unlikely all of them can be assembled and served in a trivial manner - for instance, in a single container. As complexity grows, it becomes more and more important to be able to scale the agents independently of the main application. Additionally, it may be desirable to reuse agents over different teams, and even applications.\n",
    "\n",
    "These considerations are of course not unique to AI applications, and have been addressed in the past by the microservices architecture.\n",
    "\n",
    "This is where the concept of remote agents comes in. Remote agents are agents that are not part of the main application, but are instead running in a separate process, possibly on a separate machine/container. The main application communicates with these agents over a network, using either HTTP or gRPC protocols.\n",
    "\n",
    "## Usage\n",
    "\n",
    "Remote agents we very easy to use. You can host any existing agents (even basic `Askable`s) as remote agents by using any of the `AskableHost` classes. Then, you can use the `RemoteAskable` class to switchin any agent with it remote counterpart.\n",
    "\n",
    "**NOTE** these examples also include response streaming, but is not mandatory.\n",
    "\n",
    "## REST\n",
    "\n",
    "This notebook demonstrates how to use remote agents with REST protocol. Please looks at other notebooks for gRPC protocol variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to sys.path\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('../vanilla_aiagents')))\n",
    "\n",
    "from vanilla_aiagents.agent import Agent\n",
    "from vanilla_aiagents.workflow import Workflow, Conversation\n",
    "from vanilla_aiagents.llm import AzureOpenAILLM\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAILLM({\n",
    "    \"azure_deployment\": os.getenv(\"AZURE_OPENAI_MODEL\"),\n",
    "    \"azure_endpoint\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"api_key\": os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    \"api_version\": os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "})\n",
    "\n",
    "# Set logging to debug for Agent, User and Workflow\n",
    "import logging\n",
    "\n",
    "# Set logging to debug for Agent, User, and Workflow\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"vanilla_aiagents.agent\").setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"vanilla_aiagents.workflow\").setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"vanilla_aiagents.llm\").setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"vanilla_aiagents.remote.remote\").setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1 = Agent(id=\"agent1\", llm=llm, description=\"Call this agent for general purpose questions\", system_message = \"\"\"You are an AI assistant\n",
    "    Your task is to help the user with their questions.\n",
    "    Always respond with the best answer you can generate.\n",
    "    If you don't know the answer, respond with \"I don't know\".\n",
    "    Always be polite and helpful.\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vanilla_aiagents.remote.remote import RESTHost, RemoteAskable, RESTConnection\n",
    "\n",
    "host = RESTHost(askables=[agent1], host=\"127.0.0.1\", port=5001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host.start()\n",
    "connection = RESTConnection(url=\"http://localhost:5001\")\n",
    "remote = RemoteAskable(id=\"agent1\",connection=connection)\n",
    "flow = Workflow(askable=remote, conversation=Conversation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async for step in flow.run_stream(\"Which is the capital of France?\"):\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
