{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent routing via available tooling\n",
    "\n",
    "When configuring a `Team`, you normally provide a brie description of each `Agent` to the orchestrator will have enough information to pick the best-suited one next in the conversation.\n",
    "\n",
    "Usually, a good description should include the agent purpose and its main capabilities. However, this may get more complex and less manageable as the agents evolve and their purpose is adjusted, leading to the change of improper routing due to the orchestrator not having accurate information.\n",
    "\n",
    "A complementary approach is to also tell the orchestrator to look at each `Agent` available tools. This can also help to route to an agent given a specific user asks that maps to a function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to sys.path\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('../vanilla_aiagents')))\n",
    "\n",
    "from vanilla_aiagents.agent import Agent\n",
    "from vanilla_aiagents.workflow import Workflow\n",
    "from vanilla_aiagents.team import Team\n",
    "from vanilla_aiagents.llm import AzureOpenAILLM\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAILLM({\n",
    "    \"azure_deployment\": os.getenv(\"AZURE_OPENAI_MODEL\"),\n",
    "    \"azure_endpoint\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"api_key\": os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    \"api_version\": os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "})\n",
    "\n",
    "# Set logging to debug for Agent, User and Workflow\n",
    "import logging\n",
    "\n",
    "# Set logging to debug for Agent, User, and Workflow\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"vanilla_aiagents.agent\").setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"vanilla_aiagents.workflow\").setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"vanilla_aiagents.llm\").setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent description here is purposely vague\n",
    "first = Agent(id=\"first\", llm=llm, description=\"Agent1\", system_message = \"\"\"You are part of an AI process\n",
    "Your task is to support the user inquiry by providing the user profile.\n",
    "\"\"\")\n",
    "\n",
    "@first.register_tool(name=\"get_product_info\", description=\"Get the product info\")\n",
    "def get_product_info():\n",
    "    return \"Product info: Product A\"\n",
    "\n",
    "# And here as well\n",
    "second = Agent(id=\"second\", llm=llm, description=\"Agent2\", system_message = \"\"\"You are part of an AI process\n",
    "Your task is to support the user inquiry by providing the user balance.\n",
    "\"\"\")\n",
    "\n",
    "@second.register_tool(name=\"get_user_balance\", description=\"Get the user balance\")\n",
    "def get_user_balance():\n",
    "    return \"User balance: $100\"\n",
    "\n",
    "# include_tools_descriptions is set to True\n",
    "flow = Team(id=\"flow\", description=\"\", members=[first, second], llm=llm, stop_callback=lambda conv: len(conv.messages) > 2, include_tools_descriptions=True, use_structured_output=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = Workflow(askable=flow)\n",
    "workflow.restart()\n",
    "\n",
    "workflow.run(\"Which is my current balance?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.conversation.messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
