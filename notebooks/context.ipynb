{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation context\n",
    "\n",
    "This notebook shows how to leverage *conversation variables* to keep track of the conversation context beyond message history, so they don't get polluted with context information. Key differentiator between conversation variables and message history is that the former is not visible to the user, and will only keep the latest value set during the conversation.\n",
    "\n",
    "Typical usage includes:\n",
    "\n",
    "- the channel where the conversation is happening\n",
    "- the user's language\n",
    "- the user's timezone or location\n",
    "- intermediate results or workflow step tracking\n",
    "\n",
    "Of course, you can store any other information that you want to keep track of during the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to sys.path\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('../vanilla_aiagents')))\n",
    "\n",
    "from vanilla_aiagents.agent import Agent\n",
    "from vanilla_aiagents.workflow import Workflow\n",
    "from vanilla_aiagents.sequence import Sequence\n",
    "from vanilla_aiagents.llm import AzureOpenAILLM\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAILLM({\n",
    "    \"azure_deployment\": os.getenv(\"AZURE_OPENAI_MODEL\"),\n",
    "    \"azure_endpoint\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"api_key\": os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    \"api_version\": os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "})\n",
    "\n",
    "# Set logging to debug for Agent, User and Workflow\n",
    "import logging\n",
    "\n",
    "# Set logging to debug for Agent, User, and Workflow\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"vanilla_aiagents.agent\").setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"vanilla_aiagents.workflow\").setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"vanilla_aiagents.llm\").setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we will store the user's language and the channel where the conversation is happening with a \"first\" agent. Then, we will use a \"second\" agent to show how to access this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telling the agents to set context variables implies calling a pre-defined function call\n",
    "first = Agent(id=\"first\", llm=llm, description=\"First agent\", system_message = \"\"\"You are part of an AI process\n",
    "Your task is to set a context for the next agent to continue the conversation.\n",
    "\n",
    "DO set context variable \"CHANNEL\" to \"voice\" and \"LANGUAGE\" to \"en\"\n",
    "\n",
    "DO respond only \"Context set\" when you are done.\n",
    "\"\"\")\n",
    "\n",
    "# Second agent might have its system message extended automatically with the context from the ongoing conversation\n",
    "# \"__context__\" is a special marker that will be replaced with the context set by the previous agent\n",
    "second = Agent(id=\"second\", llm=llm, description=\"Second agent\", system_message = \"\"\"You are part of an AI process\n",
    "Your task is to continue the conversation based on the context set by the previous agent.\n",
    "When asked, you can use variable provide in CONTEXT to generate the response.\n",
    "\n",
    "--- CONTEXT ---\n",
    "__context__\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = Sequence(id=\"flow\", description=\"\", steps=[first, second], llm=llm)\n",
    "workflow = Workflow(askable=flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.restart()\n",
    "workflow.run(\"Which channel is this conversation on?\")\n",
    "workflow.conversation.messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
